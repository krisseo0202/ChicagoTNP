{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import s3fs\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.66\n",
      "0.5.1\n"
     ]
    }
   ],
   "source": [
    "print(boto3.__version__)\n",
    "print(s3fs.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data Stored at S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "path = 's3://chicagobucket/data/TNP_Trips.csv'\n",
    "mykey = '########################'\n",
    "mysecret = '############################'\n",
    "# s3fs has to be version 0.3.0 or higher to use dask dataframe\n",
    "aws_chicago_df = dd.read_csv(path, storage_options = {'key': mykey, 'secret': mysecret}, dtype={'Trip Seconds': 'float64', 'Tip':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# of Rows:  Delayed('int-3fad9342-9866-4259-9782-ab86f1de17ba')\n",
      "\n",
      "# of Columns:  21\n",
      "\n",
      "Name of Columns:  ['Trip ID', 'Trip Start Timestamp', 'Trip End Timestamp', 'Trip Seconds', 'Trip Miles', 'Pickup Census Tract', 'Dropoff Census Tract', 'Pickup Community Area', 'Dropoff Community Area', 'Fare', 'Tip', 'Additional Charges', 'Trip Total', 'Shared Trip Authorized', 'Trips Pooled', 'Pickup Centroid Latitude', 'Pickup Centroid Longitude', 'Pickup Centroid Location', 'Dropoff Centroid Latitude', 'Dropoff Centroid Longitude', 'Dropoff Centroid Location']\n",
      "\n",
      "Total Missing values :  dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray>\n",
      "\n",
      "\n",
      "Trip ID                        object\n",
      "Trip Start Timestamp           object\n",
      "Trip End Timestamp             object\n",
      "Trip Seconds                  float64\n",
      "Trip Miles                    float64\n",
      "Pickup Census Tract           float64\n",
      "Dropoff Census Tract          float64\n",
      "Pickup Community Area         float64\n",
      "Dropoff Community Area        float64\n",
      "Fare                          float64\n",
      "Tip                           float64\n",
      "Additional Charges            float64\n",
      "Trip Total                    float64\n",
      "Shared Trip Authorized           bool\n",
      "Trips Pooled                    int64\n",
      "Pickup Centroid Latitude      float64\n",
      "Pickup Centroid Longitude     float64\n",
      "Pickup Centroid Location       object\n",
      "Dropoff Centroid Latitude     float64\n",
      "Dropoff Centroid Longitude    float64\n",
      "Dropoff Centroid Location      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n# of Rows: \", aws_chicago_df.shape[0])\n",
    "print(\"\\n# of Columns: \", aws_chicago_df.shape[1])\n",
    "print('\\nName of Columns: ', aws_chicago_df.columns.tolist())\n",
    "print(\"\\nTotal Missing values : \", aws_chicago_df.isnull().sum().values.sum())\n",
    "print('\\n')\n",
    "print(aws_chicago_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Snappy Compressed Parquet File from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = wr.s3.read_parquet(path='s3://chicagobucket/date_data/trip_start_date=2018-11-01/', dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Splited and Converted 1.4 million rows of data starting November 2018 to September 2020 reported by Transportation Network Providers into 700 daily snappy compressed parquet files using AWS Athena. Directly loading 43GB csv file caused Jupyter Notebook to freeze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Queries:\n",
    "``` mysql\n",
    "CREATE TABLE chicago AS \n",
    "SELECT \"trip id\" as trip_id,\n",
    "date_parse(\"trip start timestamp\", '%m/%d/%Y %h:%i:%s %p') as trip_start_timestamp,\n",
    "date_parse(\"trip end timestamp\", '%m/%d/%Y %h:%i:%s %p') as trip_end_timestamp,\n",
    "DATE(date_parse(\"trip start timestamp\", '%m/%d/%Y %h:%i:%s %p')) as trip_start_date,\n",
    "HOUR(date_parse(\"trip start timestamp\", '%m/%d/%Y %h:%i:%s %p')) as trip_start_hour,\n",
    "\"trip seconds\" as trip_seconds,\n",
    "\"trip miles\" as trip_miles,\n",
    "\"pickup census tract\" as pickup_census_tract,\n",
    "\"dropoff census tract\" as dropoff_census_tract,\n",
    "\"fare\" as fare,\n",
    "\"tip\" as tip,\n",
    "\"additional charges\" as additional_charges,\n",
    "\"trip total\" as trip_total,\n",
    "\"shared trip authorized\" as shared_trip_authorized,\n",
    "\"trips pooled\" as trips_pooled,\n",
    "\"pickup centroid latitude\" as pickup_latitude,\n",
    "\"pickup centroid longitude\"as pickup_longitude,\n",
    "\"dropoff centroid latitude\" as dropoff_latitude,\n",
    "\"dropoff centroid longitude\" as dropoff_longitude\n",
    "FROM data;\n",
    "```\n",
    "\n",
    "Use Partitioned By = 'trip_start_date' to split the data into daily data \n",
    "``` mysql\n",
    "CREATE TABLE parquet_from_to\n",
    "WITH (format='PARQUET', parquet_compression='SNAPPY', \n",
    "      partitioned_by = array['trip_start_date'], external_location = 's3://chicagobucket/date_data/') AS\n",
    "SELECT trip_start_timestamp,\n",
    "         trip_end_timestamp,\n",
    "        trip_start_hour,\n",
    "         trip_seconds,\n",
    "         trip_miles,\n",
    "         pickup_census_tract,\n",
    "         dropoff_census_tract,\n",
    "         pickup_community_area,\n",
    "         dropoff_community_area,\n",
    "         fare,\n",
    "        tip,\n",
    "        additional_charges,\n",
    "        trip_total,\n",
    "        shared_trip_authorized,\n",
    "         trips_pooled,\n",
    "         pickup_latitude,\n",
    "         pickup_longitude,\n",
    "         dropoff_latitude,\n",
    "         dropoff_longitude,\n",
    "         trip_start_date\n",
    "FROM chicago_parquet\n",
    "WHERE trip_start_date\n",
    "    BETWEEN DATE('from') 'ex) from = \"2020-09-30\"'\n",
    "        AND DATE('to') 'ex) to = \"2020-09-30\"'\n",
    "```\n",
    "\n",
    "To sync AWS S3 Folder, type aws s3 sync s3://mybucket .ON your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
